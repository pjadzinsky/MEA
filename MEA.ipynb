{
 "metadata": {
  "name": "MEA"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import meaRecording\n",
      "import numpy as np\n",
      "\n",
      "def analysePD(wildcard, whiteThresholdFactor=.8):\n",
      "  '''\n",
      "    Load and analyse the photodiode associated with all files that match wildcard in current folder\n",
      "    \n",
      "    Parameters:\n",
      "    -----------\n",
      "    wildcard:            string to match files, uses fnmatch, see its help if needed but * and ? are acceptable\n",
      "    whiteThresholdFactor:      a number between 0 and 1, although the code is not checking for it and code will not crash with numbers outside this range.\n",
      "                         white frames are defined as any crossing of threshold where threshold is whiteTrheshold*maxValueInRecording\n",
      "    \n",
      "    Output:\n",
      "    -------\n",
      "    startTimes:      list with times where a stimulus started\n",
      "    endTimes:        list with times where a stimulus ended\n",
      "    period:          distance in between white frames for a given stimulus\n",
      "  '''\n",
      "  \n",
      "  # generate a ndarray with all the scans corresonding to a white frame and a list with the average number of scans per frame per file\n",
      "  #\n",
      "  whiteFrameScans, scansperframe, scanRate = loadAllWhiteFrames(wildcard, whiteThresholdFactor)\n",
      "  print 'finished loading all whiteFrames from', wildcard\n",
      "  \n",
      "  # At this point I have finished loading PD from all files and extracting all possible white frames.\n",
      "  # Remove those white frames that are of no interest, that where detected because we are probably not flipping stimulus ever frame\n",
      "  whiteFrameScans = keepOnlyFirstWhite(whiteFrameScans, scansperframe)    # this is a list\n",
      "  \n",
      "  # Make a list with those items that correspond to the 1st white frame for a given experiment.\n",
      "  # By a change in experiment I mean that the period in between white frames changes. It can also change if experiment is skipping frames.\n",
      "  # next line is somewhat complicated, to understand it. If needed right in a piece of paper the sequence of scans corresponding to whiteFrames\n",
      "  # then we want to compute the distance between those consecutive scans but at the end, we care about the change in distance, that\n",
      "  # is why we have to compare 3 consecutive whiteFrameScans. Also, independently of the computation, we always want to return the 1st element in the list\n",
      "  firstWhiteIndex = [item for item in range(len(whiteFrameScans)-1) if whiteFrameScans[item+1]+whiteFrameScans[item-1]-2*whiteFrameScans[item]>scansperframe.mean()/2 or item==0]\n",
      "  \n",
      "  # Make a list with indexes into lastWhiteFrames per stim. This list, as firstWhiteIndex does not hold times not scans but indexes into whiteFrameScans\n",
      "  lastWhiteIndex = [firstWhiteIndex[item]-1 for item in range(1,len(firstWhiteIndex))]\n",
      "  lastWhiteIndex.append(len(whiteFrameScans)-1)\n",
      "  \n",
      "  # make the following lists:\n",
      "  # Time of 1st white in a given experiment.\n",
      "  startTimes = [whiteFrameScans[index]/float(scanRate) for index in firstWhiteIndex]\n",
      "  # period between whiteFrames of a given stimulus\n",
      "  period = [(whiteFrameScans[index+1] - whiteFrameScans[index])/float(scanRate) for index in firstWhiteIndex]\n",
      "  # end of the experiment\n",
      "  endTimes = [whiteFrameScans[index]/float(scanRate)+period[i] for i, index in enumerate(lastWhiteIndex)]\n",
      "  \n",
      "  #                st whites and another with their corresponding periods\n",
      "  return startTimes, endTimes, period\n",
      "\n",
      "def loadAllWhiteFrames(wildcard, whiteThresholdFactor):\n",
      "  '''\n",
      "    For all files in current directory that match wildcard, open one at a time and extract all the scans corresponding to PD\n",
      "    where whiteThreshold is crossed. For each file, load PD, compute the maximum value in the PD and define as threshold anything that\n",
      "    crosses that value * whiteThresholdFactor\n",
      "    ***********************\n",
      "    VERY IMPORTANT, this will produce random white frames if there are absolutely no white frames in the PD recording\n",
      "    ***********************\n",
      "    \n",
      "    Parameters:\n",
      "    -----------\n",
      "    whildcard:      a string matching all files to be analyzed, see fnmatch for syntax but (* and ? are accepted)\n",
      "    whiteThresholdFactor:  a number between 0 and 1, although the code is not checking for it and any number will work\n",
      "    \n",
      "    Output:\n",
      "    -------\n",
      "    whiteFrameScans:     ndarray with the scans corresponding to the white frames\n",
      "    scansperframe:       estimated number of scans per frame\n",
      "    scanRate:            from the file's header, how many samples per second are we recording.\n",
      "    '''\n",
      "  import os\n",
      "  import fnmatch\n",
      "  from numpy import append\n",
      "  \n",
      "  # init the ndarray to hold all white frames detected across all files.\n",
      "  allWhiteScans = np.arange(0)\n",
      "  accumulatedScans = 0\n",
      "  \n",
      "  # init a ndarray to hold the average number of scans per frame, will have one item per file loaded\n",
      "  scansperframe = np.arange(0)\n",
      "  \n",
      "  for file in os.listdir(os.getcwd()):\n",
      "    if fnmatch.fnmatch(file, wildcard):\n",
      "      print 'Working on file', file\n",
      "      \n",
      "      header = meaRecording.getRecordingHeader(file)\n",
      "      nscans = header['nscans']\n",
      "      scanRate = header['scanRate']\n",
      "      \n",
      "      # load PD, each item corresponds to 1/scanrate seconds\n",
      "      pd = loadPD(file)\n",
      "      \n",
      "      # Get the number of scans per frame\n",
      "      scansperframe = np.append(scansperframe, getScansPerFrame(pd))\n",
      "      \n",
      "      # detect the maximum value in pd_array\n",
      "      pd_max = np.max(pd)\n",
      "      \n",
      "      # define threshold that has to be crossed to define a white pd.\n",
      "      whiteThreshold = pd_max*whiteThresholdFactor\n",
      "      \n",
      "      # detect crossings of threshold\n",
      "      # all crossings are detected, if stimulus is apdating every n frames, each white frame will be detected n times\n",
      "      whiteFrameScans = findThresholdCrossing(pd, whiteThreshold)    # this is ndarray\n",
      "      \n",
      "      # shift the scans to take into account that we are not loading the 1st file\n",
      "      whiteFrameScans += accumulatedScans\n",
      "      \n",
      "      # update accumulatedScans\n",
      "      accumulatedScans += nscans\n",
      "      \n",
      "      # append white frames for current file to list with all white frames\n",
      "      allWhiteScans = np.append(allWhiteScans, whiteFrameScans)\n",
      "  \n",
      "  return allWhiteScans, scansperframe, scanRate\n",
      "\n",
      "def findThresholdCrossing(array, threshold):\n",
      "  '''\n",
      "    Find the indexes and value of array for which threshold is crossed in the upwards direction\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    array: ndarray with ints or floats\n",
      "    \n",
      "    threshold: an int or float value\n",
      "    \n",
      "    Output:\n",
      "    -------\n",
      "    crossings: a list of 'index', 'value' pairs\n",
      "    \n",
      "    '''\n",
      "  shifted = np.concatenate([[np.min(array)],array[:-1]])<threshold\n",
      "  crossings = array>=threshold\n",
      "  crossings *= shifted\n",
      "  \n",
      "  return np.nonzero(crossings)[0]\n",
      "\n",
      "def loadPD(filename, maxTime = 1650):\n",
      "  # load the PD\n",
      "  header = meaRecording.getRecordingHeader(filename)\n",
      "  fileLength = header['nscans']/header['scanRate']\n",
      "  pd_array = meaRecording.getChannel(0, maxTime, filename)\n",
      "  \n",
      "  return pd_array\n",
      "\n",
      "def getScansPerFrame(pd, estimatedFramePeriod=.01, scanrate=10000):\n",
      "  '''\n",
      "    compute the frameperiod from a PD recording.\n",
      "    Algorithm computes the FFT of the PD and checks the freq of the maxima.\n",
      "    If any of the first 100 freq is close to 1/estimatedFramePeriod then\n",
      "    returns that value\n",
      "    \n",
      "    Parameters:\n",
      "    -----------\n",
      "    pd: ndarray with pd values, might be the output of loadPD('file.bin', 10)\n",
      "    \n",
      "    estimatedFramePeriod: 1/framerate in the stimulating monitor\n",
      "    \n",
      "    scanrate: comes from the recording's header\n",
      "    header = meaRecording.getRecordingHeader('030713a.bin')\n",
      "    header['scanRate']\n",
      "    \n",
      "    Output:\n",
      "    -------\n",
      "    frameperiod: returns the average frame period in seconds.\n",
      "    framesamples: average number of samples at scanrate per frame (framesamples = frameperiod*scanrate\n",
      "    \n",
      "    '''\n",
      "  import scipy\n",
      "  import scipy.fftpack\n",
      "  \n",
      "  # FFT the signal\n",
      "  pdFFT = scipy.fftpack.rfft(pd)\n",
      "  pdFreqs = scipy.fftpack.rfftfreq(pdFFT.size, 1./scanrate)\n",
      " \n",
      "  # loop through the 100 frequencies with stronger FFT and if frameperiod is close to the estimated one, return it\n",
      "  for i in range(100):\n",
      "    fftmaxarg = pdFFT.argmax()\n",
      "    maxargfreq = pdFreqs[fftmaxarg]\n",
      "\n",
      "    if maxargfreq==0:\n",
      "\t\tframeperiod=0;\n",
      "    else:\n",
      "\t    frameperiod = 1./maxargfreq\n",
      "    #print fftmaxarg, maxargfreq, frameperiod\n",
      "    \n",
      "    if abs(frameperiod-estimatedFramePeriod)<estimatedFramePeriod*.2:\n",
      "      framesamples = frameperiod*scanrate\n",
      "      return framesamples\n",
      "    \n",
      "    # current maxargfreq was not close to estimated one, remove the max and keep looping\n",
      "    pdFFT[fftmaxarg]=0\n",
      "  \n",
      "  # if I got here it means that non of the first 100 maxima had a freq matching estimated one\n",
      "  sys.exit('frameperiod failure: None of the 100 most relevant frequencies matched the corresponding to estimatedFramePeriod')\n",
      "\n",
      "def keepOnlyFirstWhite(whiteFrameScans, scansPerFrame):\n",
      "  '''\n",
      "    Compute the distance (in scans) between a white frame (at position n) and the previous one; if the distance is comparable to scansPerFrame\n",
      "    remove whiteFrameScan at position n.\n",
      "    \n",
      "    Parameters:\n",
      "    -----------\n",
      "    whiteFrameScans: ndarray\n",
      "    output of findThresholdCrossing(pd, whiteThreshold)\n",
      "    scansperframe:   output of frameperiod(pd)\n",
      "    \n",
      "    Output:\n",
      "    -------\n",
      "    whiteFrameScans:  ndarray with the scans corresponding to white frames\n",
      "    \n",
      "    Comments:\n",
      "    ---------\n",
      "    whiteFrameScans has the points in the photodiode recording at which threshold was crossed.\n",
      "    whiteFrameScans is also a link to the time of such events since each point is spaced on average every 1/scanRate seconds\n",
      "    '''\n",
      "  # subtract from every element in whiteFrameScans the previous element. Subtract 0 from the 1st element\n",
      "  dist = whiteFrameScans[:]-np.concatenate([[0], whiteFrameScans[0:-1]])\n",
      "  \n",
      "  whiteFrameScans = [whiteFrameScans[item] for item, distance in enumerate(dist) if distance > scansPerFrame.mean()*1.5 or item==0]\n",
      "  return whiteFrameScans\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ~/Documents/Notebook/python/AnalysePD/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ~/Documents/Notebook/Experiments/2014/140411/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open('140411a.bin', 'rb')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numpy import fromfile"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f.seek(0)\n",
      "a=fromfile(f, '>u4', 1)[0]; print 0, a\n",
      "a=fromfile(f, '>i2', 1)[0]; print 1, a\n",
      "a=fromfile(f, '>i2', 1)[0]; print 2, a\n",
      "a=fromfile(f, '>u4', 1)[0]; print 3, a\n",
      "a=fromfile(f, '>u4', 1)[0]; print 4, a\n",
      "b=[]\n",
      "for i in range(a):\n",
      "    b.append(fromfile(f, '>i2', 1)[0])\n",
      "a=fromfile(f, '>f4',1)[0]; print 5, a\n",
      "a=fromfile(f, '>u4', 1)[0]; print 6, a\n",
      "a=fromfile(f, '>f4', 1)[0]; print 7, a\n",
      "a=fromfile(f, '>f4', 1)[0]; print 8, a\n",
      "a=fromfile(f, '>i4', 1)[0]; print 9, a\n",
      "a=fromfile(f, 'a'+str(a), 1)[0]; print a\n",
      "a=fromfile(f, '>i4', 1)[0]; print a\n",
      "a=fromfile(f, 'a'+str(a), 1)[0]; print a\n",
      "a=fromfile(f, '>i4', 1)[0]; print a\n",
      "a=fromfile(f, 'a'+str(a), 1)[0]; print a\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numpy import fromfile\n",
      "from numpy import zeros\n",
      "\n",
      "def getRecordingHeader(filename):\n",
      "  '''\n",
      "    read header from an Igor generated recording with MEArecording\n",
      "    \n",
      "    input\n",
      "    -----\n",
      "    filename: the experiment to load from\n",
      "    \n",
      "    output\n",
      "    ------\n",
      "    header: a dictionary with key:value pairs\n",
      "    '''\n",
      "  f = open(filename, 'rb')\n",
      "  # http://docs.scipy.org/doc/numpy/user/basics.rec.html explains numpy formats\n",
      "  # '> / <' bid endian, little endian\n",
      "  # b, i, u, f, c, a refer to bit, integer, unsigned, float, complex, string\n",
      "  # the number following is the number of bites.\n",
      "  # for example '>u4' = Big Endian unsigned 4 bytes\n",
      "  header = {}\n",
      "  header['headerSize'] = fromfile(f, '>u4', 1)[0]\n",
      "  header['type'] = fromfile(f, '>i2', 1)[0] # 32 bit big endian unsigned\n",
      "  header['version'] = fromfile(f, '>i2', 1)[0]\n",
      "  header['nscans'] = fromfile(f, '>u4', 1)[0]\n",
      "  header['numberOfChannels'] = fromfile(f, '>u4', 1)[0]\n",
      "  header['whichChan'] = []\n",
      "  for i in range(header['numberOfChannels']):\n",
      "        header['whichChan'].append(fromfile(f, '>i2', 1)[0])\n",
      "        \n",
      "  header['scanRate'] = fromfile(f, '>f4',1)[0]\n",
      "  header['blockSize'] = fromfile(f, '>u4', 1)[0]\n",
      "  header['scaleMult'] = fromfile(f, '>f4',1)[0]\n",
      "  header['scaleOff'] = fromfile(f, '>f4', 1)[0]\n",
      "  header['dateSize'] = fromfile(f, '>i4', 1)[0]\n",
      "  header['dateStr'] = fromfile(f, 'a'+str(header['dateSize']), 1)[0]\n",
      "  header['timeSize'] = fromfile(f, '>i4', 1)[0]\n",
      "  header['timeStr'] = fromfile(f, 'a'+str(header['timeSize']), 1)[0]\n",
      "  header['userSize'] = fromfile(f, '>i4', 1)[0]\n",
      "  header['userStr'] = fromfile(f, 'a'+str(header['userSize']), 1)[0]\n",
      "  f.close\n",
      "  return header\n",
      "\n",
      "def getChannel(chan,length, filename):\n",
      "  '''\n",
      "    load a channel form an igor generated binary experimental file\n",
      "    \n",
      "    Inputs\n",
      "    ------\n",
      "    chan: channel number to be loaded\n",
      "    0, photodiode\n",
      "    length: amount of time to load in seconds\n",
      "    \n",
      "    filename: the file to load from\n",
      "    \n",
      "    output\n",
      "    ------\n",
      "    channel: 1D ndarray\n",
      "  '''\n",
      "  \n",
      "  header = getRecordingHeader(filename)\n",
      "  blockSize = header['blockSize']\n",
      "  # Change length into scans or number of scans\n",
      "  scansRequested = int(length*header['scanRate'])\n",
      "  # Make sure that the scansRequested is not bigger than the scans available\n",
      "  scansRequested = min(scansRequested, header['nscans'])\n",
      "  # I'm going to loop through the file, adding scans until scansNeeded < 0\n",
      "  scansNeeded = scansRequested\n",
      "\n",
      "  # Generate output, an ndarray of blockTime  = []\n",
      "  output = zeros(scansRequested)\n",
      "  f = open(filename)\n",
      "  block = 0\n",
      "  while scansNeeded>0:\n",
      "    # get ready to read next block corresponding to channel in question\n",
      "    f.seek(header['headerSize']+block*blockSize*header['numberOfChannels']*2+chan*blockSize*2)\n",
      "    \n",
      "    # figure out if we are going to pull down the whole block or just a fraction\n",
      "    scansAdded = min(scansNeeded, blockSize)\n",
      "\n",
      "    currentSamples = fromfile(f, '>f2', scansAdded)\n",
      "    output[block*blockSize:block*blockSize+len(currentSamples)] = currentSamples\n",
      "\n",
      "    scansNeeded -= scansAdded\n",
      "    block += 1\n",
      "\n",
      "  f.close()\n",
      "  return output\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "getRecordingHeader('140411a.bin')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}